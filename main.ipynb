{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "datapath = '/kaggle/input/lgg-mri-segmentation/kaggle_3m/'\n",
    "\n",
    "DATA = []\n",
    "\n",
    "# Reading all file directories into DataFrame of columns [scanID, scanpath, maskpath]\n",
    "for scanID in os.listdir(datapath):\n",
    "    if scanID not in ['README.md', 'data.csv']:\n",
    "        for sliceID in os.listdir(datapath + scanID):\n",
    "            if '_mask' not in sliceID:\n",
    "                DATA.append([scanID, datapath + scanID + '/' + sliceID, datapath + scanID + '/' + sliceID[:-4] + '_mask' + sliceID[-4:] ])\n",
    "                \n",
    "DATA = pd.DataFrame(DATA, columns = ['scanID', 'scanpath', 'maskpath'])\n",
    "SCANID_LIST = DATA['scanID'].unique()\n",
    "DATA.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(im):\n",
    "    '''\n",
    "        Takes in np array of shape H*W*3 or Tensor of\n",
    "        shape 3*H*W, displays it.\n",
    "    '''\n",
    "    if im.shape[0] == 3:\n",
    "        im = np.moveaxis(im.cpu().detach().numpy(), 0, -1)\n",
    "    plt.figure()\n",
    "    plt.imshow(im)\n",
    "\n",
    "import re\n",
    "LAST_NUMBER_RE = re.compile('.*_(\\d+).*')\n",
    "def last_number(imname):\n",
    "    '''\n",
    "        Takes in string of image name, returns identifying\n",
    "        number at the end of the image name.\n",
    "    '''\n",
    "    search = LAST_NUMBER_RE.search(imname)\n",
    "    return int(search.groups()[0])\n",
    "\n",
    "def order_filenames(filenames):\n",
    "    '''\n",
    "        Sorts image names by identifying number at the end.\n",
    "    '''\n",
    "    return sorted(\n",
    "        filenames,\n",
    "        key = lambda slice : last_number(slice[1]['scanpath'])\n",
    "    )\n",
    "\n",
    "def compare_segmentation(im, mask):\n",
    "    '''\n",
    "        Takes in Image and Mask, displays them side by side.\n",
    "    '''\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.imshow(im)\n",
    "    ax2.imshow(mask)\n",
    "    ax1.set_title('Image')\n",
    "    ax2.set_title('Mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "images = []\n",
    "masks  = []\n",
    "\n",
    "# Index of patients' images to look at\n",
    "SCANID_IDX = 6\n",
    "\n",
    "# Select all images with this patient's index\n",
    "for index, slice in order_filenames(\n",
    "    DATA[DATA['scanID'] == SCANID_LIST[SCANID_IDX] ].iterrows() ):\n",
    "    im   = cv2.imread(slice['scanpath'])\n",
    "    mask = cv2.imread(slice['maskpath'])\n",
    "    images.append(im)\n",
    "    masks.append(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "pca_eigenvector_project = PCA() # So we don't keep remaking our PCA object\n",
    "def eigenvector_project(image, channel_first = False):\n",
    "    '''\n",
    "        Args:\n",
    "            image:\n",
    "                (H, W, 3) numpy array\n",
    "        Desc:\n",
    "            Orthogonal projection from image RGB point cloud to \n",
    "            their eigenvectors after centering\n",
    "        Returns:\n",
    "            (256, 256, 3) numpy array\n",
    "    '''\n",
    "    global pca_eigenvector_project\n",
    "    if image.shape == (3, 256, 256):\n",
    "        image = np.moveaxis(image, 0, -1)\n",
    "    if channel_first:\n",
    "        return np.moveaxis(pca_eigenvector_project.fit_transform(image.reshape(-1, 3) ).reshape(256, 256, 3), -1, 0)\n",
    "    else:\n",
    "        return pca_eigenvector_project.fit_transform(image.reshape(-1, 3) ).reshape(256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "masks  = []\n",
    "for index, row in DATA.iterrows():\n",
    "    images.append( eigenvector_project(cv2.imread(row['scanpath']), channel_first = True ) )\n",
    "    masks.append( eigenvector_project(cv2.imread(row['maskpath']), channel_first = True ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def CUDA_load(dataset, transpose_data = False, dtype_X = torch.float, dtype_y = torch.float):\n",
    "    '''\n",
    "        Pass in iterable in form [ (X0, y0), ..., (Xn, yn) ] (transpose_data = False) \n",
    "        or [ (X0, ..., Xn), (y0, ..., yn) ] (transpose_data = True), as well as \n",
    "        data types to convert X and y to if defaults are not desired.\n",
    "        \n",
    "        Returns object to pass into DataLoader as 'dataset' argument. Done this way to\n",
    "        allow for custom DataLoader to be used.\n",
    "    '''\n",
    "    if not transpose_data:\n",
    "        return list([torch.tensor(X, device = 'cuda', dtype = dtype_X), torch.tensor(y, device = 'cuda', dtype = dtype_y)] for X, y in dataset)\n",
    "    else:\n",
    "        return list([torch.tensor(X, device = 'cuda', dtype = dtype_X), torch.tensor(y, device = 'cuda', dtype = dtype_y)] for X, y in zip(*dataset) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset as DSMixin, DataLoader\n",
    "\n",
    "class ShuffleLoader(DSMixin):\n",
    "    '''\n",
    "        Standard torch.utils.data.DataLoader, with reassigned batches every\n",
    "        run-through to prevent overfitting to one batch distribution.\n",
    "    '''\n",
    "    def __init__(self, dataset, batch_size, shuffle = True):\n",
    "        super().__init__()\n",
    "        self.loader = torch.utils.data.DataLoader(\n",
    "            dataset = dataset,\n",
    "            batch_size = batch_size,\n",
    "            shuffle = shuffle\n",
    "        )\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "    \n",
    "    def __iter__(self):\n",
    "        def next_generator(loader_instance):\n",
    "            for X in loader_instance.loader:\n",
    "                yield X\n",
    "            loader_instance.loader = torch.utils.data.DataLoader(\n",
    "                dataset = loader_instance.dataset,\n",
    "                batch_size = loader_instance.batch_size,\n",
    "                shuffle = loader_instance.shuffle\n",
    "            )\n",
    "        return next_generator(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# We will use 70-15-15 train/val/test\n",
    "\n",
    "image_train, image_test, mask_train, mask_test = train_test_split(\n",
    "    images, masks,\n",
    "    train_size = .6\n",
    ")\n",
    "\n",
    "image_val, image_test, mask_val, mask_test = train_test_split(\n",
    "    image_test, mask_test,\n",
    "    train_size = .5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_CUDA = CUDA_load([image_train, mask_train], transpose_data= True)\n",
    "val_dataset_CUDA = CUDA_load([image_val, mask_val], transpose_data= True)\n",
    "test_dataset_CUDA = CUDA_load([image_test, mask_test], transpose_data= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_loader = ShuffleLoader(dataset = train_dataset_CUDA, batch_size = BATCH_SIZE)\n",
    "val_loader = ShuffleLoader(dataset = val_dataset_CUDA, batch_size = BATCH_SIZE)\n",
    "test_loader = ShuffleLoader(dataset = test_dataset_CUDA, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOSS FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tversky_loss(input, target, eps= 1, alpha= .5, beta= .5):\n",
    "    '''\n",
    "        Args:\n",
    "            input:\n",
    "                Predicted Tensor to gauge accuracy of. Same size as target.\n",
    "            target:\n",
    "                Target Tensor to use as ground truth. Same size as input.\n",
    "            eps:\n",
    "                Smoothing value to ensure no division by zero.\n",
    "            alpha:\n",
    "                Weight to put on False Positives. Higher value penalizes more.\n",
    "                Value of .5 for alpha & beta results in standard DICE loss.\n",
    "            beta:\n",
    "                Weight to put on False Negatives. Higher value penalizes more.\n",
    "                Value of .5 for alpha & beta results in standard DICE loss.\n",
    "        Desc:\n",
    "            Tversky Loss is DICE Loss (IoU) with separate weights put on\n",
    "            False Positives and False Negatives. The Union calculation for\n",
    "            the denominator is framed as:\n",
    "                Union = True Positive + False Positive + False Negative\n",
    "            This allows us to put separate weights on False Positives and\n",
    "            False Negatives, leading to the calculation:\n",
    "                Union = True Positive + alpha * False Positive + beta * False Negative\n",
    "            Values of .5 for both parameters create the standard DICE loss.\n",
    "            Values lie in domain (0, inf).\n",
    "        Returns:\n",
    "            Tensor containing 1 - Tversky coefficient, optimal when minimized @ 0.\n",
    "    '''\n",
    "    # Flattens mask to single binary image since all 3 channels are the same\n",
    "    # for all masks in the batch\n",
    "    target = target[:,0,:,:].reshape(-1)\n",
    "    input  = input.reshape(-1)\n",
    "\n",
    "    true_pos = (input * target).sum()    \n",
    "    false_pos = ( (1-target) * input).sum()\n",
    "    false_neg = (target * (1-input) ).sum()\n",
    "    tversky_coef = (true_pos + eps) / (true_pos + alpha*false_pos + beta*false_neg + eps)  \n",
    "\n",
    "    return 1 - tversky_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DICE_loss(input, target, eps= 1e-5):\n",
    "    '''\n",
    "        Args:\n",
    "            input:\n",
    "                Predicted Tensor to gauge accuracy of. Same size as target.\n",
    "            target:\n",
    "                Target Tensor to use as ground truth. Same size as input.\n",
    "            eps:\n",
    "                Smoothing value to ensure no division by zero.\n",
    "        Desc:\n",
    "            DICE Loss function computes 1 - DICE coefficient. DICE coefficient\n",
    "            is representation of Intersection over Union. Formula is:\n",
    "                2 * |Input && Target| / ( |Input| + |Target| )\n",
    "            For |...| sybolizing cardinality of a set.\n",
    "            Since input can include soft probabilities as well as hard 1/0,\n",
    "            the cardinality of an input is the sum.\n",
    "        Returns:\n",
    "            Tensor containing 1 - DICE coefficient, optimal when minimized @ 0\n",
    "    '''\n",
    "    intersection = (input * target).view(input.shape[0], -1).sum(axis= -1)\n",
    "    union = input.view(input.shape[0], -1).sum(axis= -1) + target.view(target.shape[0], -1).sum(axis= -1)\n",
    "    return (1 - 2*intersection/(union + eps) ).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpConv2d_2x2(nn.Module):\n",
    "    '''\n",
    "        Up-Convolution operation that consists of Bilinear upsampling +\n",
    "        2x2 Convolution\n",
    "    '''\n",
    "    def __init__(self, in_channels, out_channels, padding= 1):\n",
    "        super().__init__()\n",
    "        self.pipeline= nn.Sequential(\n",
    "            nn.Upsample(scale_factor= 2, mode= 'bilinear'),   \n",
    "            # Top left of 2x2 Conv filter is output location, so we may pad bottom+right by 1\n",
    "            nn.ReflectionPad2d(padding= (0, padding, 0, padding) ),\n",
    "            nn.Conv2d(in_channels= in_channels, out_channels= out_channels, kernel_size= 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.pipeline(X)\n",
    "\n",
    "class SingleImageSegmenter5(nn.Module):\n",
    "    '''\n",
    "        Convolutional Autoencoder with Residual Connections (U-Net with modifications). \n",
    "        Generates binary segmentation mask for single image, given single image as input.\n",
    "        In contrast to a multi-scan model, which this model can be used in a pipeline of.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder_block_1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.Conv2d(in_channels= 3, out_channels= 16, kernel_size= 3, padding= 1), # 256 * 256 * 3 -> 256 * 256 * 16\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels= 16, out_channels= 16, kernel_size= 3, padding= 1), # 256 * 256 * 16 -> 256 * 256 * 16\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "\n",
    "        self.encoder_block_2 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size= 2, stride= 2), # 256 * 256 * 16 -> 128 * 128 * 16\n",
    "            nn.Conv2d(in_channels= 16, out_channels= 32, kernel_size= 3, padding= 1), # 128 * 128 * 16 -> 128 * 128 * 32\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels= 32, out_channels= 32, kernel_size= 3, padding= 1), # 128 * 128 * 32 -> 128 * 128 * 32\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "\n",
    "        self.encoder_block_3 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size= 2, stride= 2), # 128 * 128 * 32 -> 64 * 64 * 32\n",
    "            nn.Conv2d(in_channels= 32, out_channels= 64, kernel_size= 3, padding= 1), # 64 * 64 * 32 -> 64 * 64 * 64\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels= 64, out_channels= 64, kernel_size= 3, padding= 1), # 64 * 64 * 64 -> 64 * 64 * 64\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.latent_block = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size= 2, stride= 2), # 64 * 64 * 64 -> 32 * 32 * 64\n",
    "            nn.Conv2d(in_channels= 64, out_channels= 128, kernel_size= 3, padding= 1), # 32 * 32 * 64 -> 32 * 32 * 128\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels= 128, out_channels= 64, kernel_size= 3, padding= 1), # 32 * 32 * 128 -> 32 * 32 * 64\n",
    "            nn.LeakyReLU(),\n",
    "            UpConv2d_2x2(in_channels= 64, out_channels= 64), # 32 * 32 * 64 -> 64 * 64 * 64\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.decoder_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 128, out_channels= 64, kernel_size= 3, padding= 1), # 64 * 64 * 128 -> 64 * 64 * 64\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels= 64, out_channels= 32, kernel_size= 3, padding= 1), # 64 * 64 * 64 -> 64 * 64 * 32\n",
    "            nn.LeakyReLU(),\n",
    "            UpConv2d_2x2(in_channels= 32, out_channels= 32), # 64 * 64 * 32 -> 128 * 128 * 32\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "\n",
    "        self.decoder_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 64, out_channels= 32, kernel_size= 3, padding= 1), # 128 * 128 * 64 -> 128 * 128 * 32\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels= 32, out_channels= 16, kernel_size= 3, padding= 1), # 128 * 128 * 32 -> 128 * 128 * 16\n",
    "            nn.LeakyReLU(),\n",
    "            UpConv2d_2x2(in_channels= 16, out_channels= 16), # 128 * 128 * 16 -> 256 * 256 * 16\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "\n",
    "        self.decoder_block_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 32, out_channels= 16, kernel_size= 3, padding= 1), # 256 * 256 * 32 -> 256 * 256 * 16\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels= 16, out_channels= 8, kernel_size= 3, padding= 1), # 256 * 256 * 16 -> 256 * 256 * 8\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels= 8, out_channels= 1, kernel_size= 1), # 256 * 256 * 8 -> 256 * 256 * 1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X_resout_1 = self.encoder_block_1(X)\n",
    "        X_resout_2 = self.encoder_block_2(X_resout_1)\n",
    "        X_resout_3 = self.encoder_block_3(X_resout_2)\n",
    "        X_resin_1 = self.latent_block(X_resout_3)\n",
    "        X_resin_1 = torch.cat([\n",
    "            X_resin_1,\n",
    "            X_resout_3\n",
    "        ],\n",
    "        dim= 1)\n",
    "\n",
    "        X_resin_2 = self.decoder_block_1(X_resin_1)\n",
    "        X_resin_2 = torch.cat([\n",
    "            X_resin_2,\n",
    "            X_resout_2\n",
    "        ],\n",
    "        dim= 1)\n",
    "\n",
    "        X_resin_3 = self.decoder_block_2(X_resin_2)\n",
    "        X_resin_3 = torch.cat([\n",
    "            X_resin_3,\n",
    "            X_resout_1\n",
    "        ],\n",
    "        dim= 1)\n",
    "\n",
    "        return self.decoder_block_3(X_resin_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "def train(net, train_loader, val_loader, learning_rate, loss_function, epochs):\n",
    "    optimizer = Adam(params = net.parameters(), lr = learning_rate)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0\n",
    "        \n",
    "        net.train()\n",
    "        for batchnum, (image, mask) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            pred = net(image/255)\n",
    "            loss = loss_function(pred, mask/255)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            training_loss += loss.item()\n",
    "        \n",
    "        print(\"Training loss for epoch {} is {}\".format(epoch, training_loss/(batchnum+1) ) )\n",
    "        \n",
    "        net.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batchnum, (image, mask) in enumerate(val_loader):\n",
    "                pred = net(image/255)\n",
    "                val_loss += loss_function(pred, mask/255).item()\n",
    "        \n",
    "        print(\"Val loss for epoch {} is {}\".format(epoch, val_loss/(batchnum+1) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SingleImageSegmenter5().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(net, train_loader, val_loader, learning_rate = .0001,\n",
    "      loss_function = DICE_loss, epochs = 2)\n",
    "# Both DICE_loss and tversky_loss are provided here, can use native PyTorch losses as well. \n",
    "# Toggle loss & tversky coefficients periodically depending on model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "torch.save(net.state_dict(), \"model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
